<?xml version="1.0" encoding="UTF-8"?>
<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema"
    targetNamespace="github.com/agentflare-ai/agentml-go/openai"
    xmlns:openai="github.com/agentflare-ai/agentml-go/openai"
    xmlns:agentml="github.com/agentflare-ai/agentml"
    elementFormDefault="qualified">

    <xs:annotation>
        <xs:documentation> OpenAI Extension for AgentML - LLM integration via OpenAI-compatible APIs
            Namespace: github.com/agentflare-ai/agentml-go/openai Providers: OpenAI, Azure OpenAI,
            vLLM, LocalAI, Ollama, any OpenAI-compatible endpoint </xs:documentation>
    </xs:annotation>

    <xs:import namespace="github.com/agentflare-ai/agentml"
        schemaLocation="https://xsd.agentml.dev/agentflare-ai/agentml/agentml.xsd">
        <xs:annotation>
            <xs:documentation> Imports agentml:executable. openai:generate substitutes into this
                group for use in state machine executable content. </xs:documentation>
        </xs:annotation>
    </xs:import>

    <xs:element name="generate" substitutionGroup="agentml:executable">
        <xs:annotation>
            <xs:documentation> LLM content generation executable with two modes: MODE 1 - Function
                Calling: LLM drives state transitions via send()/cancel() functions - location:
                optional - Example: &lt;openai:generate model="gpt-4o" prompt="Route this request"
                /&gt; MODE 2 - Content Generation: LLM generates text stored in data model -
                location: REQUIRED - Example: &lt;openai:generate model="gpt-4" prompt="Summarize:
                {{.text}}" location="summary" /&gt; REQUIREMENTS: - model OR modelexpr (required) -
                prompt OR promptexpr OR child &lt;prompt&gt; elements (required) - Multiple prompt
                sources concatenated: prompt + promptexpr + child prompts (in order) TEMPLATE SYNTAX
                (Go templates): - {{.var}} - variable access - {{.obj.field}} - nested field - {{if
                .cond}}...{{end}} - conditional - {{range .items}}...{{end}} - iteration </xs:documentation>
        </xs:annotation>
        <xs:complexType>
            <xs:sequence>
                <xs:element name="prompt" minOccurs="0" maxOccurs="unbounded">
                    <xs:annotation>
                        <xs:documentation> Child prompt element for structured multi-part prompts.
                            Supports Go template syntax. Multiple prompts concatenated in document
                            order. Combined with parent prompt/promptexpr if present. </xs:documentation>
                    </xs:annotation>
                    <xs:complexType>
                        <xs:simpleContent>
                            <xs:extension base="xs:string" />
                        </xs:simpleContent>
                    </xs:complexType>
                </xs:element>
            </xs:sequence>

            <xs:attribute name="model" type="xs:string">
                <xs:annotation>
                    <xs:documentation> Model identifier. Required unless modelexpr provided. If both
                        present, modelexpr takes precedence. Common: "gpt-4o" | "gpt-4-turbo" |
                        "gpt-4" | "gpt-3.5-turbo" Azure: use deployment name </xs:documentation>
                </xs:annotation>
            </xs:attribute>

            <xs:attribute name="modelexpr" type="xs:string">
                <xs:annotation>
                    <xs:documentation> Data model expression evaluating to model name. Required
                        unless model provided. Takes precedence over model. Examples:
                        userPrefs.model | config['model'] | selectModel(task) </xs:documentation>
                </xs:annotation>
            </xs:attribute>

            <xs:attribute name="prompt" type="xs:string">
                <xs:annotation>
                    <xs:documentation> Prompt text with Go template support. Required unless
                        promptexpr or child prompts provided. Concatenated before promptexpr and
                        child prompts if multiple sources present. Examples: "Analyze {{.input}}" |
                        "{{if .urgent}}URGENT: {{end}}{{.msg}}" </xs:documentation>
                </xs:annotation>
            </xs:attribute>

            <xs:attribute name="promptexpr" type="xs:string">
                <xs:annotation>
                    <xs:documentation> Data model expression evaluating to prompt string. Required
                        unless prompt or child prompts provided. Concatenated after prompt
                        attribute, before child prompts if multiple sources present. Examples:
                        prompts[type] | buildPrompt(ctx) | `Process: ${data}` </xs:documentation>
                </xs:annotation>
            </xs:attribute>

            <xs:attribute name="location" type="xs:string">
                <xs:annotation>
                    <xs:documentation> Data model path for storing response. REQUIRED in content
                        generation mode (no tools). OPTIONAL in function calling mode. If
                        stream=true, updated incrementally. Examples: "result" | "data.summary" |
                        "items[0]" </xs:documentation>
                </xs:annotation>
            </xs:attribute>

            <xs:attribute name="stream" type="xs:boolean" default="false">
                <xs:annotation>
                    <xs:documentation> Enable incremental streaming. Default: false true: lower
                        latency, incremental updates, higher overhead (use for interactive) false:
                        single response, lower overhead (use for batch) </xs:documentation>
                </xs:annotation>
            </xs:attribute>

            <xs:anyAttribute namespace="##other" processContents="lax" />
        </xs:complexType>
    </xs:element>

</xs:schema>